[{"title":"My first Post","url":"/2022/05/28/My-first-Post/","content":"<p>And here we start a new journey.</p>\n<p>pic bed test: </p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220522223044162.png\" alt=\"image-20220522223044162\"></p>\n","tags":["Hexo"]},{"title":"lenet5","url":"/2022/08/20/lenet5/","content":"<h1 id=\"lenet5简易实现\"><a href=\"#lenet5简易实现\" class=\"headerlink\" title=\"lenet5简易实现\"></a>lenet5简易实现</h1><p>朱子康(<a href=\"mailto:&#x73;&#112;&#122;&#101;&#110;&#111;&#64;&#49;&#54;&#51;&#46;&#x63;&#111;&#109;\">&#x73;&#112;&#122;&#101;&#110;&#111;&#64;&#49;&#54;&#51;&#46;&#x63;&#111;&#109;</a>)</p>\n<p>二零二二年七月十六日</p>\n<p>摘要：本报告为2022级ERCESI新硕士研究生培训第一阶段LAB1报告。<a href=\"https://github.com/spzeno/lenet5.git\">GitHub Repo</a></p>\n<h3 id=\"实验内容概述\"><a href=\"#实验内容概述\" class=\"headerlink\" title=\"实验内容概述\"></a>实验内容概述</h3><p>纯c实现lenet5，不得调用第三方库，权重数据已经给出。</p>\n<h4 id=\"lenet5结构\"><a href=\"#lenet5结构\" class=\"headerlink\" title=\"lenet5结构\"></a>lenet5结构</h4><p>LeNet 是几种神经网络的统称，它们是 Yann LeCun 等人在 1990 年代开发的。一般认为，它们是最早的<strong>卷积神经网络</strong>（Convolutional Neural Networks, CNNs）。模型接收灰度图像，并输出其中包含的手写数字。LeNet 包含了以下三个模型：</p>\n<ul>\n<li>LeNet-1：5 层模型，一个简单的 CNN。</li>\n<li>LeNet-4：6 层模型，是 LeNet-1 的改进版本。</li>\n<li>LeNet-5：7 层模型，最著名的版本。</li>\n</ul>\n<p>本次实现的lenet5模型的结构如下图所示。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220716150406656.png\" alt=\"image-20220716150406656\"></p>\n<h4 id=\"参数分析\"><a href=\"#参数分析\" class=\"headerlink\" title=\"参数分析\"></a>参数分析</h4><table>\n<thead>\n<tr>\n<th>Layer</th>\n<th>Output Size</th>\n<th>Weight Size</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Input</td>\n<td>1 x 28 x 28</td>\n<td></td>\n</tr>\n<tr>\n<td>Conv(C_out&#x3D;6,K&#x3D;5,P&#x3D;0,S&#x3D;1)</td>\n<td>6 x 24 x 24</td>\n<td>6 x 1 x 5 x 5</td>\n</tr>\n<tr>\n<td>ReLU</td>\n<td>6 x 24 x 24</td>\n<td></td>\n</tr>\n<tr>\n<td>MaxPool(K&#x3D;2,S&#x3D;2)</td>\n<td>6 x 12 x 12</td>\n<td></td>\n</tr>\n<tr>\n<td>Conv(C_out&#x3D;16,K&#x3D;5,P&#x3D;0,S&#x3D;1)</td>\n<td>16 x 8 x 8</td>\n<td>16 x 6 x 5 x 5</td>\n</tr>\n<tr>\n<td>ReLU</td>\n<td>16 x 8 x 8</td>\n<td></td>\n</tr>\n<tr>\n<td>MaxPool(K&#x3D;2,S&#x3D;2)</td>\n<td>16 x 4 x 4</td>\n<td></td>\n</tr>\n<tr>\n<td>Flatten</td>\n<td>256</td>\n<td></td>\n</tr>\n<tr>\n<td>Linear(256-&gt;128)</td>\n<td>128</td>\n<td>256*128</td>\n</tr>\n<tr>\n<td>ReLU</td>\n<td>128</td>\n<td></td>\n</tr>\n<tr>\n<td>Linear(128-&gt;84)</td>\n<td>84</td>\n<td>128*84</td>\n</tr>\n<tr>\n<td>ReLU</td>\n<td>84</td>\n<td></td>\n</tr>\n<tr>\n<td>Linear(84-&gt;10)</td>\n<td>10</td>\n<td>84*10</td>\n</tr>\n<tr>\n<td>ReLU</td>\n<td>10</td>\n<td></td>\n</tr>\n</tbody></table>\n<h3 id=\"算法及流程\"><a href=\"#算法及流程\" class=\"headerlink\" title=\"算法及流程\"></a>算法及流程</h3><h4 id=\"待测试集合处理\"><a href=\"#待测试集合处理\" class=\"headerlink\" title=\"待测试集合处理\"></a>待测试集合处理</h4><p>由于png图片采用了从LZ77派生的无损数据压缩算法且每个pixel由RGB和α通道值表示，纯c语言读取png图片并转换为位图难度较大，因此我们使用如下Python脚本对20张png图片进行预处理，得到mnist ubyte格式（不包含头部）的image-ubyte文件和label-ubyte文件。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">from</span> array <span class=\"keyword\">import</span> *</span><br><span class=\"line\"></span><br><span class=\"line\">dirname = <span class=\"string\">&#x27;./image&#x27;</span></span><br><span class=\"line\">data_image = array(<span class=\"string\">&#x27;B&#x27;</span>)</span><br><span class=\"line\">data_label = array(<span class=\"string\">&#x27;B&#x27;</span>)</span><br><span class=\"line\">FileList = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> filename <span class=\"keyword\">in</span> os.listdir(dirname):</span><br><span class=\"line\">  <span class=\"keyword\">if</span> filename.endswith(<span class=\"string\">&quot;.png&quot;</span>):</span><br><span class=\"line\">    FileList.append(os.path.join(dirname,filename))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> filename <span class=\"keyword\">in</span> FileList:</span><br><span class=\"line\">  label = <span class=\"built_in\">int</span>(filename.split(<span class=\"string\">&#x27;/&#x27;</span>)[<span class=\"number\">2</span>][<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">  Im = Image.<span class=\"built_in\">open</span>(filename)</span><br><span class=\"line\"></span><br><span class=\"line\">  pixel = Im.load()</span><br><span class=\"line\">  width, height = Im.size</span><br><span class=\"line\">  <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,width):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>,height):</span><br><span class=\"line\">      data_image.append(pixel[y,x])</span><br><span class=\"line\">  data_label.append(label) </span><br><span class=\"line\"></span><br><span class=\"line\">output_file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;image-ubyte&#x27;</span>, <span class=\"string\">&#x27;wb&#x27;</span>)</span><br><span class=\"line\">data_image.tofile(output_file)</span><br><span class=\"line\">output_file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;label-ubyte&#x27;</span>, <span class=\"string\">&#x27;wb&#x27;</span>)</span><br><span class=\"line\">data_label.tofile(output_file)</span><br><span class=\"line\">output_file.close()</span><br></pre></td></tr></table></figure>\n\n<p>将<code>COUNT_TEST</code>个ubyte格式的28x28 8bit灰度图数据存储在全局变量<code>uint8 imageSet[COUNT_TEST][28][28];</code>，相应的标签存储在<code>uint8 labelSet[COUNT_TEST];</code>，涉及到的读取函数如下</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">read_data</span><span class=\"params\">(<span class=\"type\">const</span> <span class=\"type\">char</span> data_file[], <span class=\"type\">const</span> <span class=\"type\">char</span> label_file[])</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tFILE* fp_image = fopen(data_file, <span class=\"string\">&quot;rb&quot;</span>);</span><br><span class=\"line\">\tFILE* fp_label = fopen(label_file, <span class=\"string\">&quot;rb&quot;</span>);</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> (!fp_image || !fp_label) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">\tfseek(fp_image, <span class=\"number\">0</span>, SEEK_SET);   <span class=\"comment\">//已经去掉头部数据</span></span><br><span class=\"line\">\tfseek(fp_label, <span class=\"number\">0</span>, SEEK_SET);</span><br><span class=\"line\">\tfread(imageSet, <span class=\"keyword\">sizeof</span>(*imageSet) * COUNT_TEST, <span class=\"number\">1</span>, fp_image);</span><br><span class=\"line\">\tfread(labelSet, COUNT_TEST, <span class=\"number\">1</span>, fp_label);</span><br><span class=\"line\">\tfclose(fp_image);</span><br><span class=\"line\">\tfclose(fp_label);</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"预处理权重数据并读取\"><a href=\"#预处理权重数据并读取\" class=\"headerlink\" title=\"预处理权重数据并读取\"></a>预处理权重数据并读取</h4><p>c1、c2、d1、d2、d3权重数据的最后一列为bias数据，为了方便我们将最后一列提取出来，预处理权重数据得到</p>\n<ul>\n<li>c1层对应的卷积<code>w0_1</code>和<code>bias0_1</code></li>\n<li>c2层对应的卷积<code>w2_3</code>和<code>bias2_3</code></li>\n<li>d1层对应的卷积<code>w4_5</code>和<code>bias4_5</code></li>\n<li>d2层对应的卷积<code>w5_6</code>和<code>bias5_6</code></li>\n<li>d3层对应的卷积<code>w6_7</code>和<code>bias6_7</code></li>\n</ul>\n<p>预处理得到的数据在源代码文件夹下。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220718134409955.png\" alt=\"image-20220718134409955\"></p>\n<p>使用全局变量存储权重数据，如下所示。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//weights</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> INPUT\t\t\t1</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LAYER1\t\t\t6</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LAYER2\t\t\t6</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LAYER3\t\t\t16</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LAYER4\t\t\t16</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LAYER5\t\t\t128</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LAYER6\t\t\t84</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LAYER7          10</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_KERNEL_0_1\t5</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_KERNEL_2_3\t5</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_KERNEL_4_5\t4</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_KERNEL_5_6\t1</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_KERNEL_6_7\t1</span></span><br><span class=\"line\"><span class=\"type\">double</span> weight0_1[INPUT][LAYER1][LENGTH_KERNEL_0_1][LENGTH_KERNEL_0_1];</span><br><span class=\"line\"><span class=\"type\">double</span> weight2_3[LAYER2][LAYER3][LENGTH_KERNEL_2_3][LENGTH_KERNEL_2_3];</span><br><span class=\"line\"><span class=\"type\">double</span> weight4_5[LAYER4][LAYER5][LENGTH_KERNEL_4_5][LENGTH_KERNEL_4_5];</span><br><span class=\"line\"><span class=\"type\">double</span> weight5_6[LAYER5][LAYER6][LENGTH_KERNEL_5_6][LENGTH_KERNEL_5_6];</span><br><span class=\"line\"><span class=\"type\">double</span> weight6_7[LAYER6][LAYER7][LENGTH_KERNEL_6_7][LENGTH_KERNEL_6_7];</span><br><span class=\"line\"><span class=\"type\">double</span> bias0_1[LAYER1];</span><br><span class=\"line\"><span class=\"type\">double</span> bias2_3[LAYER3];</span><br><span class=\"line\"><span class=\"type\">double</span> bias4_5[LAYER5];</span><br><span class=\"line\"><span class=\"type\">double</span> bias5_6[LAYER6];</span><br><span class=\"line\"><span class=\"type\">double</span> bias6_7[LAYER7];</span><br></pre></td></tr></table></figure>\n\n<p>接下来从预处理得到的数据文件中读取数据到上述保存权重数据的全局变量中，为了方便起见，使用了宏函数如下，举例来说，当需要读取<code>c1</code>层的权重数据时，只需<code>readWeightMat(&quot;w0_1&quot;,LENGTH_KERNEL_0_1,INPUT,weight0_1); readBias(&quot;bias0_1&quot;,bias0_1);</code>即可。</p>\n<p>需要注意的是，由于提供的权重数据的组织形式和上述定义的保存权重数据的全局变量的组织形式的差异，<strong>我们需要根据当前读取索引<code>idx</code>确定当前读取到的权重值的存储位置</strong>，也即四维数组w的4个下标的表达式。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> readWeightMat(FILE_MAT, KERNELSIZE, frontLayerSize,w)\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#123;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tFILE* f = fopen(FILE_MAT, <span class=\"string\">&quot;r&quot;</span>);\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t<span class=\"keyword\">if</span> (!f) return 1;\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tdouble tmp = 0;\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tint idx = 0;\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\twhile (fscanf(f, <span class=\"string\">&quot;%lf&quot;</span>, &amp;tmp) != EOF) &#123;\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\tw[idx / KERNELSIZE / KERNELSIZE % frontLayerSize][idx / KERNELSIZE / KERNELSIZE /  frontLayerSize][idx / KERNELSIZE % KERNELSIZE][idx % KERNELSIZE] = tmp; \\</span></span><br><span class=\"line\"><span class=\"meta\">\t\tidx++;\t\t\t\t\t\t\t\t\t\t\t\t    \\</span></span><br><span class=\"line\"><span class=\"meta\">\t&#125;\t\t\t\t\t\t\t\t\t\t\t\t\t\t    \\</span></span><br><span class=\"line\"><span class=\"meta\">\tfclose(f);\t\t\t\t\t\t\t\t\t\t\t\t    \\</span></span><br><span class=\"line\"><span class=\"meta\">&#125;  </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> readBias(FILE_MAT, w)\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#123;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tFILE* f = fopen(FILE_MAT, <span class=\"string\">&quot;r&quot;</span>);\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t<span class=\"keyword\">if</span> (!f) return 1;\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tdouble tmp = 0;\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tint idx = 0;\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\twhile (fscanf(f, <span class=\"string\">&quot;%lf&quot;</span>, &amp;tmp) != EOF) &#123;\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\tw[idx++] = tmp;\t\t\t\t\t\t\t\t\t        \\</span></span><br><span class=\"line\"><span class=\"meta\">\t&#125;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tfclose(f);\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#125;  </span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"predict\"><a href=\"#predict\" class=\"headerlink\" title=\"predict\"></a>predict</h4><p>循环读取<code>imageSet</code>每一张待测试图到<code>input</code>，<code>predict</code>图片对应的值并与<code>label</code>进行比较。</p>\n<p>使用全局变量存储各层的特征图，如下所示。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//feature maps</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_FEATURE0\t28</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_FEATURE1\t(LENGTH_FEATURE0 - LENGTH_KERNEL_0_1 + 1)  <span class=\"comment\">//24</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_FEATURE2\t(LENGTH_FEATURE1 &gt;&gt; 1)                 <span class=\"comment\">//12</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_FEATURE3\t(LENGTH_FEATURE2 - LENGTH_KERNEL_2_3 + 1)  <span class=\"comment\">//8</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span>\tLENGTH_FEATURE4\t(LENGTH_FEATURE3 &gt;&gt; 1)\t\t\t       <span class=\"comment\">//4</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_FEATURE5\t(LENGTH_FEATURE4 - LENGTH_KERNEL_4_5+ 1)  <span class=\"comment\">//1</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_FEATURE6\t1</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> LENGTH_FEATURE7\t1</span></span><br><span class=\"line\"><span class=\"type\">double</span> input[INPUT][LENGTH_FEATURE0][LENGTH_FEATURE0];</span><br><span class=\"line\"><span class=\"type\">double</span> layer1[LAYER1][LENGTH_FEATURE1][LENGTH_FEATURE1];</span><br><span class=\"line\"><span class=\"type\">double</span> layer2[LAYER2][LENGTH_FEATURE2][LENGTH_FEATURE2];</span><br><span class=\"line\"><span class=\"type\">double</span> layer3[LAYER3][LENGTH_FEATURE3][LENGTH_FEATURE3];</span><br><span class=\"line\"><span class=\"type\">double</span> layer4[LAYER4][LENGTH_FEATURE4][LENGTH_FEATURE4];</span><br><span class=\"line\"><span class=\"type\">double</span> layer5[LAYER5][LENGTH_FEATURE5][LENGTH_FEATURE5];</span><br><span class=\"line\"><span class=\"type\">double</span> layer6[LAYER6][LENGTH_FEATURE6][LENGTH_FEATURE6];</span><br><span class=\"line\"><span class=\"type\">double</span> layer7[LAYER7][LENGTH_FEATURE7][LENGTH_FEATURE7];</span><br></pre></td></tr></table></figure>\n\n<p><code>predict</code>函数如下所示</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\">uint8 <span class=\"title function_\">Predict</span><span class=\"params\">()</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"built_in\">memset</span>(layer1, <span class=\"number\">0</span>, LAYER1 * LENGTH_FEATURE1 * LENGTH_FEATURE1 * <span class=\"keyword\">sizeof</span>(<span class=\"type\">double</span>));</span><br><span class=\"line\">\t<span class=\"built_in\">memset</span>(layer2, <span class=\"number\">0</span>, LAYER2 * LENGTH_FEATURE2 * LENGTH_FEATURE2 * <span class=\"keyword\">sizeof</span>(<span class=\"type\">double</span>));</span><br><span class=\"line\">\t<span class=\"built_in\">memset</span>(layer3, <span class=\"number\">0</span>, LAYER3 * LENGTH_FEATURE3 * LENGTH_FEATURE3 * <span class=\"keyword\">sizeof</span>(<span class=\"type\">double</span>));</span><br><span class=\"line\">\t<span class=\"built_in\">memset</span>(layer4, <span class=\"number\">0</span>, LAYER4 * LENGTH_FEATURE4 * LENGTH_FEATURE4 * <span class=\"keyword\">sizeof</span>(<span class=\"type\">double</span>));</span><br><span class=\"line\">\t<span class=\"built_in\">memset</span>(layer5, <span class=\"number\">0</span>, LAYER5 * LENGTH_FEATURE5 * LENGTH_FEATURE5 * <span class=\"keyword\">sizeof</span>(<span class=\"type\">double</span>));</span><br><span class=\"line\">\t<span class=\"built_in\">memset</span>(layer6, <span class=\"number\">0</span>, LAYER6 * LENGTH_FEATURE6 * LENGTH_FEATURE6 * <span class=\"keyword\">sizeof</span>(<span class=\"type\">double</span>));</span><br><span class=\"line\">\t<span class=\"built_in\">memset</span>(layer7, <span class=\"number\">0</span>, LAYER7 * LENGTH_FEATURE7 * LENGTH_FEATURE7 * <span class=\"keyword\">sizeof</span>(<span class=\"type\">double</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">\tCONVOLUTION_FORWARD(input, layer1, weight0_1, bias0_1);</span><br><span class=\"line\">\tSUBSAMP_MAX_FORWARD(layer1, layer2);</span><br><span class=\"line\">\tCONVOLUTION_FORWARD(layer2, layer3, weight2_3, bias2_3);</span><br><span class=\"line\">\tSUBSAMP_MAX_FORWARD(layer3, layer4);</span><br><span class=\"line\">\tCONVOLUTION_FORWARD(layer4, layer5, weight4_5, bias4_5);</span><br><span class=\"line\">\tCONVOLUTION_FORWARD(layer5, layer6, weight5_6, bias5_6);</span><br><span class=\"line\">\tCONVOLUTION_FORWARD(layer6, layer7, weight6_7, bias6_7);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"type\">int</span> ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t<span class=\"type\">double</span> maxValue = layer7[ans][<span class=\"number\">0</span>][<span class=\"number\">0</span>];</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt; <span class=\"number\">10</span>; i++) &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (layer7[i][<span class=\"number\">0</span>][<span class=\"number\">0</span>] &gt; maxValue) &#123;</span><br><span class=\"line\">\t\t\tmaxValue = layer7[i][<span class=\"number\">0</span>][<span class=\"number\">0</span>];</span><br><span class=\"line\">\t\t\tans = i;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>宏函数<code>CONVOLUTION_FORWARD</code>和<code>SUBSAMP_MAX_FORWARD</code>如下所示。<code>SUBSAMP_MAX_FORWARD</code>使用的池化参数K&#x3D;2,S&#x3D;2，进行最大值采样。<code>CONVOLUTION_FORWARD</code>用于对上一层卷积得到下一层，其原理（循环次序）为：</p>\n<p>输出层的第<code>y</code>张图</p>\n<p>​\t输入层的第<code>x</code>张图</p>\n<p>​\t\t<code>(x,y)</code>确定需要使用的权重数组，计算输入层的第<code>y</code>张图贡献给输出层的第<code>x</code>张图的<code>每个pixel</code>的卷积值的累加量</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> CONVOLUTE_VALID(input,output,weight)\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#123;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tFOREACH(o0,GETLENGTH(output))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\tFOREACH(o1,GETLENGTH(*(output)))\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t\tFOREACH(w0,GETLENGTH(weight))\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t\t\tFOREACH(w1,GETLENGTH(*(weight)))\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t\t\t\t(output)[o0][o1] += (input)[o0 + w0][o1 + w1] * (weight)[w0][w1];\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> CONVOLUTION_FORWARD(input,output,weight,bias)\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#123;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tfor (int x = 0; x &lt; GETLENGTH(weight); ++x)\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\tfor (int y = 0; y &lt; GETLENGTH(*weight); ++y)\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t\tCONVOLUTE_VALID(input[x], output[y], weight[x][y]);\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tFOREACH(j, GETLENGTH(output))\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\tFOREACH(i, GETCOUNT(output[j]))\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t((double *)output[j])[i] = relu(((double *)output[j])[i] + bias[j]);\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">define</span> SUBSAMP_MAX_FORWARD(input,output)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#123;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tconst int len0 = GETLENGTH(*(input)) / GETLENGTH(*(output));\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tconst int len1 = GETLENGTH(**(input)) / GETLENGTH(**(output));\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tFOREACH(i, GETLENGTH(output))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tFOREACH(o0, GETLENGTH(*(output)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\tFOREACH(o1, GETLENGTH(**(output)))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t&#123;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\tint x0 = 0, x1 = 0, ismax;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\tFOREACH(l0, len0)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t\tFOREACH(l1, len1)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t&#123;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t\tismax = input[i][o0*len0 + l0][o1*len1 + l1] &gt; input[i][o0*len0 + x0][o1*len1 + x1];\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t\tx0 += ismax * (l0 - x0);\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t\tx1 += ismax * (l1 - x1);\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\t&#125;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t\toutput[i][o0][o1] = input[i][o0*len0 + x0][o1*len1 + x1];\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">\t&#125;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\\</span></span><br><span class=\"line\"><span class=\"meta\">&#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>为了尽可能复用上述<code>CONVOLUTION_FORWARD</code>宏函数，我们将最后三层flat层也表示成三维数组，即<code>layer5</code>、<code>layer6</code>、<code>layer7</code>。</p>\n<h3 id=\"实验步骤\"><a href=\"#实验步骤\" class=\"headerlink\" title=\"实验步骤\"></a>实验步骤</h3><h4 id=\"环境\"><a href=\"#环境\" class=\"headerlink\" title=\"环境\"></a>环境</h4><p>vs2022 Debug x64</p>\n<p>win10</p>\n<h4 id=\"测试结果\"><a href=\"#测试结果\" class=\"headerlink\" title=\"测试结果\"></a>测试结果</h4><h5 id=\"20张png测试集\"><a href=\"#20张png测试集\" class=\"headerlink\" title=\"20张png测试集\"></a>20张png测试集</h5><p>使用Lab1&#x2F;Data&#x2F;lenet_weights提供的参数构建的lenet5网络，对20张png处理得到的测试集，得到的测试结果如下所示。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220717192236201.png\" alt=\"image-20220717192236201\"></p>\n<h5 id=\"原始mnist测试集\"><a href=\"#原始mnist测试集\" class=\"headerlink\" title=\"原始mnist测试集\"></a>原始mnist测试集</h5><p>使用Lab1&#x2F;Data&#x2F;lenet_weights提供的参数构建的lenet5网络，mnist t10k-images-idx3-ubyte作为测试集，得到的测试结果如下所示。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220717193342925.png\" alt=\"image-20220717193342925\"></p>\n<h5 id=\"额外测试\"><a href=\"#额外测试\" class=\"headerlink\" title=\"额外测试\"></a>额外测试</h5><h6 id=\"反相处理测试集\"><a href=\"#反相处理测试集\" class=\"headerlink\" title=\"反相处理测试集\"></a>反相处理测试集</h6><p>读出每张mnist图时，将每个像素的值进行255-灰度值处理并赋值给input，进行predict得到如下结果。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220717194059859.png\" alt=\"image-20220717194059859\"></p>\n<h6 id=\"轴对称处理测试集\"><a href=\"#轴对称处理测试集\" class=\"headerlink\" title=\"轴对称处理测试集\"></a>轴对称处理测试集</h6><p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220717194833823.png\" alt=\"image-20220717194833823\"></p>\n<p>可以发现反色和轴对称处理会导致权重数据失效。</p>\n<h3 id=\"REFERENCE\"><a href=\"#REFERENCE\" class=\"headerlink\" title=\"REFERENCE\"></a>REFERENCE</h3><p><a href=\"https://blog.csdn.net/baidu_40840693/article/details/82897351?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165787826516782350816977%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=165787826516782350816977&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-3-82897351-null-null.185%5Ev2%5Econtrol&utm_term=LeNet-5%20%E7%A0%94%E4%B9%A0&spm=1018.2226.3001.4450\">LeNet-5 研习</a></p>\n<p><a href=\"https://www.ruanx.net/lenet/\">LeNet：第一个卷积神经网络</a></p>\n<p><a href=\"https://github.com/fan-wenjie/LeNet-5\">LeNet-5,Use C Program Language Without Any 3rd Library</a></p>\n<p><a href=\"https://blog.csdn.net/DarrenXf/article/details/85232255\">MNIST数据集的格式以及读取方式</a></p>\n<p><a href=\"https://www.cnblogs.com/senior-engineer/p/9548347.html\">PNG文件格式详解</a></p>\n<p><a href=\"http://yann.lecun.com/exdb/mnist/\">THE MNIST DATABASE</a></p>\n","tags":["神经网络"]},{"title":"代理技术","url":"/2022/05/28/%E4%BB%A3%E7%90%86%E6%8A%80%E6%9C%AF/","content":"<h1 id=\"代理技术\"><a href=\"#代理技术\" class=\"headerlink\" title=\"代理技术\"></a>代理技术</h1><h2 id=\"代理协议工作在哪一层\"><a href=\"#代理协议工作在哪一层\" class=\"headerlink\" title=\"代理协议工作在哪一层\"></a>代理协议工作在哪一层</h2><p>Socks代理协议是一种工作在<em><strong>线路层</strong></em>的协议，HTTP代理协议是一种工作在<em><strong>应用层</strong></em>的协议。</p>\n<h2 id=\"基于虚拟设备TUN-x2F-TAP技术的“真”全局代理\"><a href=\"#基于虚拟设备TUN-x2F-TAP技术的“真”全局代理\" class=\"headerlink\" title=\"基于虚拟设备TUN&#x2F;TAP技术的“真”全局代理\"></a>基于虚拟设备TUN&#x2F;TAP技术的“真”全局代理</h2><p> SOCKS5工作在线路层，<strong>SOCKS</strong>协议位于传输层(<strong>TCP</strong>&#x2F;<strong>UDP</strong>等)与应用层之间，所以能代理TCP和UDP的网络流量，<strong>对于之下的网络流量，就无能为力了</strong>。</p>\n<p>TUN2SOCKS使用tun网卡实现了更加底层的流量代理，这种全局代理不仅可以代理传输层流量，还可以代理其它所有应用程序的请求流量，比如代理游戏的流量，代理所有命令行工具的流量。</p>\n<p>一般的代理软件的“全局代理”指的是不论访问的IP是哪的全部都走代理，但是这种代理软件使用的代理协议的工作层次是<strong>不够底层</strong>的，在cmd会发现<strong>无法ping通google</strong>（但是<strong>使用curl却能够获得google的html内容</strong>，这是因为ping走的是ICMP而curl走的是HTTP）。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220525102729845.png\" alt=\"image-20220525102729845\"></p>\n<p>而像Netch等比较专业的代理软件则使用了tun2socks等虚拟网卡技术，在使用这种软件的全局代理时是可以在cmd中使用ping通google的。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220525103044641.png\" alt=\"image-20220525103044641\"></p>\n<p>因此，像要使用pip、apt-get等需要在shell中访问外网的场景时，强烈推荐Netch等使用基于虚拟网卡的能够代理低层数据包的软件。</p>\n<h2 id=\"如何使得虚拟机的流量也走代理\"><a href=\"#如何使得虚拟机的流量也走代理\" class=\"headerlink\" title=\"如何使得虚拟机的流量也走代理\"></a>如何使得虚拟机的流量也走代理</h2><p><strong>场景：</strong></p>\n<ol>\n<li>VMware Ubuntu虚拟机要使用apt等安装软件<em><strong>（显然我们不想搞什么换源）</strong></em></li>\n<li>开发板（例如PYNQ）上跑的Ubuntu要使用apt等安装软件<em><strong>（显然我们不想搞什么换源）</strong></em>，且开发板是通过网线与PC连接的。</li>\n</ol>\n<p><strong>方法1：</strong></p>\n<p>首先在宿主机上打开代理，并且确定<em><strong>允许其他设备连入Socks5本地端口</strong></em></p>\n<p>之后在虚拟机终端中输入以下命令：</p>\n<p><code>export  ALL_PROXY=socks5://192.168.86.1:2801</code></p>\n<p>注意更改IP和端口。</p>\n<p><strong>方法2：</strong></p>\n<p>首先需要在宿主上运行起clash，并将clash进行如下设置。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724115525450.png\" alt=\"image-20220724115525450\"></p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724122944605.png\" alt=\"image-20220724122944605\"></p>\n<p>VMware中将虚拟的网络适配器设置为NAT，取消虚拟机Ubuntu的手动DNS，设置为自动。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724120024200.png\" alt=\"image-20220724120024200\"></p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724115856787.png\" alt=\"image-20220724115856787\"></p>\n<p>设置完毕，效果如下。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724120101155.png\" alt=\"image-20220724120101155\"></p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724123536306.png\" alt=\"image-20220724123536306\"></p>\n<p>需要注意的是，这种方法设置下虽然宿主机和虚拟机均能ping通google，但是所显示的google的IP都是错误的（是一个保留IP地址），这应该与Clash TUN网卡的工作机制有关系。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724123639930.png\" alt=\"image-20220724123639930\"></p>\n<p><strong>方法3：</strong></p>\n<p>在虚拟机里直接跑clash</p>\n<h2 id=\"待研究的内容\"><a href=\"#待研究的内容\" class=\"headerlink\" title=\"待研究的内容\"></a>待研究的内容</h2><p>KCP</p>\n<p>DNS Hijack（AioDNS）</p>\n<h2 id=\"合适的软件\"><a href=\"#合适的软件\" class=\"headerlink\" title=\"合适的软件\"></a>合适的软件</h2><p>Clash真香😄</p>\n","tags":["VPN"]},{"title":"Python装饰器实现对（递归）函数运行时间计时","url":"/2022/06/04/python-decorator/","content":"<h1 id=\"Python-装饰器\"><a href=\"#Python-装饰器\" class=\"headerlink\" title=\"Python 装饰器\"></a>Python 装饰器</h1><p>场景需求：需要对函数运行时间进行计时，希望能够自动化完成计时代码的插桩工作。</p>\n<p>难点：递归函数，举例来说，假设我调用fibonacci(4)，我不希望计时只计最外层的函数，而是希望每一个被调用的fibonacci()都输出，fib的调用层次如下图所示</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220604190247526.png\" alt=\"image-20220604190247526\"></p>\n<p>也就是计时器应该输出5次函数运行耗时</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/197643740\">解决方案</a>，运行结果：</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220604190426304.png\" alt=\"image-20220604190426304\"></p>\n<p>感想（？）：Python好强大</p>\n<h1 id=\"关于Python装饰器模式和函数式编程的关系：\"><a href=\"#关于Python装饰器模式和函数式编程的关系：\" class=\"headerlink\" title=\"关于Python装饰器模式和函数式编程的关系：\"></a>关于Python装饰器模式和函数式编程的关系：</h1><h1 id=\"Python-的-Decorator\"><a href=\"#Python-的-Decorator\" class=\"headerlink\" title=\"Python 的 Decorator\"></a>Python 的 Decorator</h1><blockquote>\n<p>Python 的 Decorator 在使用上和 Java 的 Annotation（以及 C# 的 Attribute）很相似，就是在方法名前面加一个 <a href=\"https://my.oschina.net/xrf116\">@XXX</a> 注解来为这个方法装饰一些东西。但是，Java&#x2F;C# 的 Annotation 也很让人望而却步，太过于复杂了。你要玩它，需要先了解一堆 Annotation 的类库文档，感觉几乎就是在学另外一门语言。</p>\n<p>而 Python 使用了一种相对于 Decorator Pattern 和 Annotation 来说非常优雅的方法，这种方法不需要你去掌握什么复杂的 OO 模型或是 Annotation 的各种类库规定，完全就是语言层面的玩法：一种函数式编程的技巧。</p>\n<p>这是我最喜欢的一个模式了，也是一个挺好玩儿的东西，这个模式动用了函数式编程的一个技术——用一个函数来构造另一个函数。</p>\n<p>好了，我们先来点感性认识，看一个 Python 修饰器的 Hello World 代码。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">hello</span>(<span class=\"params\">fn</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">wrapper</span>():</span><br><span class=\"line\">        <span class=\"built_in\">print</span> <span class=\"string\">&quot;hello, %s&quot;</span> % fn.__name__</span><br><span class=\"line\">        fn()</span><br><span class=\"line\">        <span class=\"built_in\">print</span> <span class=\"string\">&quot;goodbye, %s&quot;</span> % fn.__name__</span><br><span class=\"line\">    <span class=\"keyword\">return</span> wrapper</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@hello</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">Hao</span>():</span><br><span class=\"line\">    <span class=\"built_in\">print</span> <span class=\"string\">&quot;i am Hao Chen&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">Hao()</span><br></pre></td></tr></table></figure>\n\n<p>代码的执行结果如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ python hello.py</span><br><span class=\"line\">hello, Hao</span><br><span class=\"line\">i am Hao Chen</span><br><span class=\"line\">goodbye, Hao</span><br></pre></td></tr></table></figure>\n\n<p>你可以看到如下的东西：</p>\n<ol>\n<li>函数<code>Hao</code>前面有个 <a href=\"https://my.oschina.net/flyinghawk\">@hello</a> 的“注解”，<code>hello</code>就是我们前面定义的函数<code>hello</code>；</li>\n<li>在<code>hello</code>函数中，其需要一个<code>fn</code>的参数（这就是用来做回调的函数）；</li>\n<li>hello 函数中返回了一个 inner 函数<code>wrapper</code>，这个<code>wrapper</code>函数回调了传进来的<code>fn</code>，并在回调前后加了两条语句。</li>\n</ol>\n<p>对于 Python 的这个 @注解语法糖（syntactic sugar）来说，当你在用某个 @decorator 来修饰某个函数<code>func</code>时，如下所示:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@decorator</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">func</span>():</span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<p>其解释器会解释成下面这样的语句：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">func = decorator(func)</span><br></pre></td></tr></table></figure>\n\n<p>嘿！这不就是把一个函数当参数传到另一个函数中，然后再回调吗？是的。但是，我们需要注意，那里还有一个赋值语句，把 decorator 这个函数的返回值赋值回了原来的<code>func</code>。</p>\n<p>我们再来看一个带参数的玩法：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">makeHtmlTag</span>(<span class=\"params\">tag, *args, **kwds</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">real_decorator</span>(<span class=\"params\">fn</span>):</span><br><span class=\"line\">        css_class = <span class=\"string\">&quot; class=&#x27;&#123;0&#125;&#x27;&quot;</span>.<span class=\"built_in\">format</span>(kwds[<span class=\"string\">&quot;css_class&quot;</span>]) \\</span><br><span class=\"line\">                                     <span class=\"keyword\">if</span> <span class=\"string\">&quot;css_class&quot;</span> <span class=\"keyword\">in</span> kwds <span class=\"keyword\">else</span> <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">def</span> <span class=\"title function_\">wrapped</span>(<span class=\"params\">*args, **kwds</span>):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"string\">&quot;&lt;&quot;</span>+tag+css_class+<span class=\"string\">&quot;&gt;&quot;</span> + fn(*args, **kwds) + <span class=\"string\">&quot;&lt;/&quot;</span>+tag+<span class=\"string\">&quot;&gt;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> wrapped</span><br><span class=\"line\">    <span class=\"keyword\">return</span> real_decorator</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@makeHtmlTag(<span class=\"params\">tag=<span class=\"string\">&quot;b&quot;</span>, css_class=<span class=\"string\">&quot;bold_css&quot;</span></span>)</span></span><br><span class=\"line\"><span class=\"meta\">@makeHtmlTag(<span class=\"params\">tag=<span class=\"string\">&quot;i&quot;</span>, css_class=<span class=\"string\">&quot;italic_css&quot;</span></span>)</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">hello</span>():</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&quot;hello world&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span> hello()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出：</span></span><br><span class=\"line\"><span class=\"comment\"># &lt;b class=&#x27;bold_css&#x27;&gt;&lt;i class=&#x27;italic_css&#x27;&gt;hello world&lt;/i&gt;&lt;/b&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>在上面这个例子中，我们可以看到：<code>makeHtmlTag</code>有两个参数。所以，为了让<code>hello = makeHtmlTag(arg1, arg2)(hello)</code>成功，<code>makeHtmlTag</code>必需返回一个 decorator（这就是为什么我们在<code>makeHtmlTag</code>中加入了<code>real_decorator()</code>）。</p>\n<p>这样一来，我们就可以进入到 decorator 的逻辑中去了——decorator 得返回一个 wrapper，wrapper 里回调<code>hello</code>。看似那个<code>makeHtmlTag()</code>写得层层叠叠，但是，已经了解了本质的我们觉得写得很自然。</p>\n<p>我们再来看一个为其它函数加缓存的示例:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> functools <span class=\"keyword\">import</span> wraps</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">memoization</span>(<span class=\"params\">fn</span>):</span><br><span class=\"line\">    cache = &#123;&#125;</span><br><span class=\"line\">    miss = <span class=\"built_in\">object</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @wraps(<span class=\"params\">fn</span>)</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">wrapper</span>(<span class=\"params\">*args</span>):</span><br><span class=\"line\">        result = cache.get(args, miss)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> result <span class=\"keyword\">is</span> miss:</span><br><span class=\"line\">            result = fn(*args)</span><br><span class=\"line\">            cache[args] = result</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> wrapper</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@memoization</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">fib</span>(<span class=\"params\">n</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> n &lt; <span class=\"number\">2</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> n</span><br><span class=\"line\">    <span class=\"keyword\">return</span> fib(n - <span class=\"number\">1</span>) + fib(n - <span class=\"number\">2</span>)</span><br></pre></td></tr></table></figure>\n\n<p>上面这个例子中，是一个斐波那契数例的递归算法。我们知道，这个递归是相当没有效率的，因为会重复调用。比如：我们要计算 fib(5)，于是其分解成<code>fib(4) + fib(3)</code>，而<code>fib(4)</code>分解成<code>fib(3) + fib(2)</code>，<code>fib(3)</code>又分解成<code>fib(2) + fib(1)</code>……你可看到，基本上来说，<code>fib(3)</code>,<code>fib(2)</code>,<code>fib(1)</code>在整个递归过程中被调用了至少两次。</p>\n<p>而我们用 decorator，在调用函数前查询一下缓存，如果没有才调用，有了就从缓存中返回值。一下子，这个递归从二叉树式的递归成了线性的递归。<code>wraps</code>的作用是保证<code>fib</code>的函数名不被<code>wrapper</code>所取代。</p>\n</blockquote>\n<p>​                                                                                                                                                          引用自<a href=\"https://mendylee.gitbooks.io/geeker-study-courses/content/bian-cheng-fan-shi-pian.html\">编程范式篇</a>，2022年8月20日记</p>\n<h1 id=\"Google-Colab\"><a href=\"#Google-Colab\" class=\"headerlink\" title=\"Google Colab\"></a>Google Colab</h1><p>测试代码：</p>\n<p><a href=\"https://colab.research.google.com/drive/1GML_i9JVwJKSGYCPL8_Mi2CXixXix6DF?usp=sharing\">https://colab.research.google.com/drive/1GML_i9JVwJKSGYCPL8_Mi2CXixXix6DF?usp=sharing</a></p>\n","tags":["Python"]},{"title":"大学","url":"/2022/07/24/%E5%A4%A7%E5%AD%A6/","content":"<h1 id=\"往事如风\"><a href=\"#往事如风\" class=\"headerlink\" title=\"往事如风\"></a>往事如风</h1><p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724145451484.png\" alt=\"image-20220724145451484\"></p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724145529969.png\" alt=\"image-20220724145529969\"></p>\n<h1 id=\"大一\"><a href=\"#大一\" class=\"headerlink\" title=\"大一\"></a>大一</h1><p>曾经想退学，就差去教务处申请了。印象中隐约记得我是去了的，并且好像碰到了同样来申请退学的人，但是我最终仍然放弃了退学。但是这些隐约的印象已经过于模糊了，我甚至无法明确这些印象是不是真实发生过的。</p>\n<p>开始刷A岛。</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724150100156.png\" alt=\"image-20220724150100156\"></p>\n<p>期末去复习</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724150321457.png\" alt=\"image-20220724150321457\"></p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724150359770.png\" alt=\"image-20220724150359770\"></p>\n<p>20190330好像是去西电打他们ACM校赛</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724151233274.png\" alt=\"image-20220724151233274\"></p>\n<p>那个时候喜欢去明远3区学</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724151415333.png\" alt=\"image-20220724151415333\"></p>\n<h1 id=\"大二\"><a href=\"#大二\" class=\"headerlink\" title=\"大二\"></a>大二</h1><p>嗯蹭的铜奖</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724151637515.png\" alt=\"image-20220724151637515\"></p>\n<p>大一嗯卷收的奖学金</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724151805136.png\" alt=\"image-20220724151805136\"></p>\n<p>下半学期就疫情了，在家嗯躺</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724152056907.png\" alt=\"image-20220724152056907\"></p>\n<p>貌似那个时候接触到了cltv？</p>\n<p><img src=\"https://md-pic-bed.oss-cn-hongkong.aliyuncs.com/img/image-20220724152147027.png\" alt=\"image-20220724152147027\"></p>\n<h1 id=\"大三\"><a href=\"#大三\" class=\"headerlink\" title=\"大三\"></a>大三</h1><p>大三开始心态就开始不行了。为了卷保研附加分，寒假参加的美赛，无果而终。</p>\n<blockquote>\n<p>今天是2022年4月9日。想写一下我从去年开始到今天的总结。</p>\n<p>去年1、2月份的时候石家庄疫情我无法回家，在长安大学校本部暂住了一段时间，那个时间段时我由于考砸了计算机网络和计算机组成，整个人处于一种非常恐慌的状态，我担心我会拿不到保研名额。那时我和pxc住一间寝室，他当时在找工作，生活非常规律，每天早起开始干活写项目，工作一整天，晚上和女朋友打个电话之后睡觉。我那时整个人处于一种非常矛盾的状态，一方面和yn、jxh组了美赛队企图拿个奖以便后边评保研资格能加分，另一方面又逃避现实每天看张顺飞、杨月等人的直播。</p>\n<p>我们美赛队啥都没搞出来。</p>\n<p>开学后疯狂卷编译原理、AI等课程。这时身边大部分人已经开始准备考研了。</p>\n<p>之后是实习，学校不知道从哪找来了个web开发的培训公司给我们培训。我那时找了个牛客大学的web求职项目，把那个配套视频完整看了一遍。这个时间点大部分考研人在实习时已经啥也不做了只学考研内容了。我印象最深的是tzr在看某个积分教学视频、ywf在机房桌子上摆了几本厚厚的法学书。</p>\n<p>之后是暑假，我这时还在想着比赛加分，看了看微信小程序开发的比赛和中科院的某个高性能比赛，最后也不了了之了，中间还去了一趟医院。</p>\n<p>我们上一届的进行毕业答辩的时候，我和以前的队友dyp有过一次短暂的交流，关于如果我被限制保本校怎么办的话题。</p>\n<p>暑期期间我参加了许多学校的夏令营，有的被老师喷的惨不忍睹，不过这段历程某种意义上确实使得我脸皮变厚了。</p>\n<p>9月份开学。</p>\n</blockquote>\n<h1 id=\"大四\"><a href=\"#大四\" class=\"headerlink\" title=\"大四\"></a>大四</h1><p>开学就是大四，我们这一届修改了保研规则且是在大四开学后才公布的文件，我记得大概是9月12号左右。鬼使神差地放弃了保内，考研去了，整个过程不可谓不痛苦。</p>\n<p>但是结果是好的，考上了，尽管如此，我目前认为我的这一次成功具有运气成分。</p>\n<p>复试通过了之后开始认真搞毕设，第一次接触到STM32和PYNQ，指导老师给的原始工程的完成度不高且没人指导我怎么用，做的过程中一度认为做不出来了要换题，不过后来还是成功搞出来了（感觉程序到处都不严谨，不过能跑就行，nobody cares）。这次经历也挺折磨的，但是可能确实训练了抗压能力。</p>\n<h1 id=\"开躺\"><a href=\"#开躺\" class=\"headerlink\" title=\"开躺\"></a>开躺</h1><p>搞完毕设就开躺了，大概是从5月份中旬开始的。由于我总感觉自己成功考上研究生有运气成分以及一些事情，导致我总有一种逃避未来的心态。后边就没干什么正经事情了，PRA的比赛没参加，折腾了一段时间的esxi和软路由、ipv6。</p>\n","tags":["生活"]}]